{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic of tensorflow and keras",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-acadYsTUZto",
        "colab_type": "text"
      },
      "source": [
        "# 1. Sample demo "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVrlOQpeQOd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "import tensorflow as tf\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDj6ridpQT85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create computing graph\n",
        "gl = tf.get_default_graph() #default graph\n",
        "w = tf.constant(2.)\n",
        "y = w+2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9WK5-BBSlk2",
        "colab_type": "code",
        "outputId": "98e147aa-4f33-489e-e462-b5638f38a7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# load session\n",
        "with tf.Session(graph=gl) as sess:\n",
        "  print(sess.run([y]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7Zvn-mLSlw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clear graph\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypgsXv-yUT3W",
        "colab_type": "text"
      },
      "source": [
        "# 2. Basics of Tensorflow  \n",
        "## concepts:\n",
        "\n",
        "- graph\n",
        "- session\n",
        "- op\n",
        "- tensor\n",
        "- variable\n",
        "- placeholder\n",
        "- path\n",
        "- tf.assign\n",
        "\n",
        "### graph \n",
        "In Tensorflow, edge represents the direction of the flows,node represents tensor and op."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18EXp8gnSl2M",
        "colab_type": "code",
        "outputId": "3d64074b-bb6e-4355-ed78-32fd61400cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# when open tensorflow, tf 会分配一个 default graph, all the op would run in this default graph.\n",
        "g0 = tf.get_default_graph()\n",
        "x0 = tf.Variable(1) # graph 的构建\n",
        "x0.graph is g0 # check graph 的构建 属不属于这个图"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9tFWJ1SSl7J",
        "colab_type": "code",
        "outputId": "e3d84f7a-8d53-4390-a148-4c4d10eaf209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# create two graphs\n",
        "g1 = tf.Graph()\n",
        "g2 = tf.Graph()\n",
        "\n",
        "# operations on g1 \n",
        "with g1.as_default():\n",
        "  x1 = tf.Variable(1)\n",
        "\n",
        "with g2.as_default():\n",
        "  x2 = tf.Variable(1)\n",
        "\n",
        "print(x1.graph is g2)\n",
        "print(x2.graph is g2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LX8ku2XSl_7",
        "colab_type": "code",
        "outputId": "ae43f47f-289d-4d0a-8da8-1948369688b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# get all the nodes in one graph\n",
        "g1.get_operations()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Operation 'Variable/initial_value' type=Const>,\n",
              " <tf.Operation 'Variable' type=VariableV2>,\n",
              " <tf.Operation 'Variable/Assign' type=Assign>,\n",
              " <tf.Operation 'Variable/read' type=Identity>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB7vAkFBSmCr",
        "colab_type": "code",
        "outputId": "28cc763e-e1f6-44cc-ee30-0615f1614785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# 当构建 graph 的时候，可能会由于重复构建导致 graph 出错，so have to clear the default graph when creating new graphs\n",
        "g_now = tf.get_default_graph()\n",
        "g_now.get_operations()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Operation 'Variable/initial_value' type=Const>,\n",
              " <tf.Operation 'Variable' type=VariableV2>,\n",
              " <tf.Operation 'Variable/Assign' type=Assign>,\n",
              " <tf.Operation 'Variable/read' type=Identity>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShyTU9sCSmFz",
        "colab_type": "code",
        "outputId": "e8f7dde2-29a5-4f4d-f04c-5ae268170c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# clear the default graphs \n",
        "tf.reset_default_graph()\n",
        "g_now = tf.get_default_graph()\n",
        "g_now.get_operations()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxzLmWlQUVyT",
        "colab_type": "text"
      },
      "source": [
        "Tensorflow 是一种静态图的学习框架，2.0 开始有动态图，Pytorch 是一种动态图的框架。动态图的好处是更符合人的编程习惯。未来的趋势是静态图、动态图相互切换。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDHMSuZJVLS8",
        "colab_type": "text"
      },
      "source": [
        "### session\n",
        "graphs don't take much resources, but session take a lot resources.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4wgWdRzSmLz",
        "colab_type": "code",
        "outputId": "d2c71fb5-1838-4273-b515-408b7d5367f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "w = tf.constant(3)\n",
        "x = w+2\n",
        "y = x +5\n",
        "z = x*3\n",
        "\n",
        "with tf.Session(graph = tf.get_default_graph()) as sess:\n",
        "  print(sess.run([x]))\n",
        "  print(sess.run([z]))\n",
        "  print(x.eval())\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5]\n",
            "[15]\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXMER-NEZCcT",
        "colab_type": "text"
      },
      "source": [
        "Tips:\n",
        "1. eval() = sess.run()\n",
        "2. tendorflow 会自动检测依赖关系\n",
        "3. 除了 variable,其余计算结果每次计算后会释放。variable 会在 session 结束后释放。\n",
        "4. 重复计算的问题。比如run 完 x 就会被释放，但run z 时需要重复计算 x; 解决方法是把 xz session 放在一起。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy_Uu8sASmPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session(graph = tf.get_default_graph()) as sess:\n",
        "  print(sess.run([x,z]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgWxoU6oSmVK",
        "colab_type": "code",
        "outputId": "b3fc7c20-1521-4980-afd0-c258832fc795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 每次使用上下文管理器太麻烦，于是我们使用有互动的session, real time feedback.\n",
        "# need to close by hand after using\n",
        "sess = tf.InteractiveSession()\n",
        "print(x.eval())\n",
        "print(sess.run([x]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "[5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txRZZO8-SmT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close()\n",
        "# variables would be released at this point."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6r5wQeCfYo1",
        "colab_type": "text"
      },
      "source": [
        "### Tensor\n",
        "There are three main sources of tensor:\n",
        "- constant (生存周期在 session 内)\n",
        "- variable \n",
        "- placeholder\n",
        "\n",
        "`tf.constant()` make new constant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EShNMux1SmSr",
        "colab_type": "code",
        "outputId": "b6019c56-bd50-4828-c7be-66477005d2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import numpy as np\n",
        "a = tf.constant(np.arange(12).reshape(3,4),dtype=tf.float32)\n",
        "with tf.Session(graph = tf.get_default_graph())as sess:\n",
        "  print(sess.run([a]))\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[ 0.,  1.,  2.,  3.],\n",
            "       [ 4.,  5.,  6.,  7.],\n",
            "       [ 8.,  9., 10., 11.]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3zqdlPlSmKg",
        "colab_type": "code",
        "outputId": "e111793e-7597-4b56-e3bc-53728bfb571b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "a = tf.constant(3.14, shape=(3,4),dtype=tf.float32)\n",
        "with tf.Session(graph = tf.get_default_graph())as sess:\n",
        "  print(sess.run([a]))\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[3.14, 3.14, 3.14, 3.14],\n",
            "       [3.14, 3.14, 3.14, 3.14],\n",
            "       [3.14, 3.14, 3.14, 3.14]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElXXnHgRDnDK",
        "colab_type": "text"
      },
      "source": [
        "### Variable\n",
        "Variable is a kind of tensor. It could be saved and updated in the session. \n",
        "\n",
        "⭐ Variables needed to be initialized, demo as following:\n",
        "\n",
        "```\n",
        "init = tf.globle_Variables_initializer() // 就不需要一个一个地初始化了\n",
        "sess.run(init)\n",
        "```\n",
        "Generally, `init` is created in the graph.\n",
        "Remark: Tndorflow usually uses `tf.Variable` and `tf.get_variable`, but these have huge differences. 尽量使用 `tf.get_variable`.\n",
        "\n",
        "### `tf.Variable`\n",
        "1. 每次调用得到的都是不同的变量，即使使用了相同的变量名，在底层实现的时候还是会为变量创建不同的别名。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQlSR_gcSmI_",
        "colab_type": "code",
        "outputId": "96ff4760-2994-475e-86cc-e1156082f47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "var1 = tf.Variable(tf.random_uniform([1],-1.0,1.0),name='var',dtype=tf.float32)\n",
        "var2 = tf.Variable(initial_value=[2],name='var',dtype=tf.float32)\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  print(var1.name,sess.run(var1))\n",
        "  print(var2.name,sess.run(var2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "var_2:0 [0.9093454]\n",
            "var_3:0 [2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTnoZ32LbA4_",
        "colab_type": "text"
      },
      "source": [
        "2. 会受`tf.name_scope` 环境的影响：会在前面加上 `name_scope` 的空间前缀。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9rjlihNSl93",
        "colab_type": "code",
        "outputId": "264095a1-0b64-47a4-9c85-14ea5f9a0a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.name_scope('var_b_scope'):\n",
        "  var1 = tf.Variable(initial_value=[2],name='var',dtype=tf.float32)\n",
        "  var2 = tf.Variable(initial_value=[2],name='var',dtype=tf.float32)\n",
        "with tf.name_scope('var_a_scope'):\n",
        "  var3 = tf.Variable(initial_value=[2],name='var',dtype=tf.float32)\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  print(var1.name,sess.run(var1))\n",
        "  print(var2.name,sess.run(var2))\n",
        "  print(var3.name,sess.run(var3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "var_b_scope/var:0 [2.]\n",
            "var_b_scope/var_1:0 [2.]\n",
            "var_a_scope/var:0 [2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBqnwXkIeRO2",
        "colab_type": "text"
      },
      "source": [
        "3. `Variable()` 在创建时可以直接指定初始化的方式，还可以把其他变量的初始值当作初始值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf6FwmG-Sl5W",
        "colab_type": "code",
        "outputId": "9e7edf3a-b5c6-4681-a85c-24dcecbb27d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "var2 = tf.Variable(var1.initialized_value())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-cc90be6b5e12>:1: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcOhUN0Leu6K",
        "colab_type": "text"
      },
      "source": [
        "### `tf.get_variable()`\n",
        "1. 只会创建一个同名的变量，如果想共享变量，需指定 `reuse = True`, 否则多次创建会导致报错。使用 `reuse = True`(not needed for the first time creating new vaviable,但须在后面共享的时候claim.)可以动态地修改某个 `scope` 的共享属性。\n",
        "\n",
        "    为什么需要共享变量？因为卷积里有一个很重要的特点是共享参数。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT1UtWxjewZb",
        "colab_type": "code",
        "outputId": "bbdea3ee-4aa2-4a27-ff23-db2ab1319815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "def func(x):\n",
        "  weight= tf.get_variable(name='weight',initializer = tf.random_normal([1]))\n",
        "  bias = tf.get_variable(name = 'bias', initializer =tf.zeros([1]))\n",
        "  return tf.add(tf.multiply(weight,x),bias)\n",
        "\n",
        "result1 = func(1)\n",
        "#result2 = func(2)\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  print(sess.run([result1]))\n",
        "  #print(sess.run([result2]))\n",
        "  \n",
        "## problem: weight and bias would run repeatly, which would cause error in tf.get_variable()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([-0.5048192], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSN2Wuw7ewtj",
        "colab_type": "code",
        "outputId": "b7663e46-e4f7-4ed4-9c8a-9303f9808dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "def func(x,reuse):\n",
        "  with tf.variable_scope('neuron',reuse = reuse): //neoron 相当于前面 var_a 的前缀: var\n",
        "    weight= tf.get_variable(name='weight',initializer = tf.random_normal([1]))\n",
        "    bias = tf.get_variable(name = 'bias', initializer =tf.zeros([1]))\n",
        "  return tf.add(tf.multiply(weight,x),bias)\n",
        "\n",
        "result1 = func(1,reuse = False)\n",
        "result2 = func(2,reuse = True) //should be double of result1\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  print(sess.run([result1]))\n",
        "  print(sess.run([result2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([0.14972697], dtype=float32)]\n",
            "[array([0.29945394], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t49nP85WprgI",
        "colab_type": "text"
      },
      "source": [
        "2. 不受 `with tf.name_scope` 的影响（是`name_scope`, not `variable_scope`; both `tf.variable` and `tf.get_variable` 都会受 `variable_scope`的影响）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO3QJ3qIeyJJ",
        "colab_type": "code",
        "outputId": "f0147dff-f902-4f77-eaa3-c4d00fe45a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.name_scope('var_a_scope'):\n",
        "  var1 = tf.get_variable(name='var',shape= [1],dtype = tf.float32)\n",
        "  var2 = tf.get_variable(name='var1',shape= [1],dtype = tf.float32)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print(sess.run([var1]))\n",
        "  print(sess.run([var2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "[array([-0.01262069], dtype=float32)]\n",
            "[array([1.5309323], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS2p4tgErRLB",
        "colab_type": "text"
      },
      "source": [
        "3. initialization\n",
        "4. `with tf.name_scope('scope name')` 会进行“累加”：每调用一次就会给里面的所有变量增加一个前缀，叠加顺序是 外层先调用的在前，后调用的在后。  \n",
        "\n",
        "### placeholder\n",
        "we need something to receive the data from outside: placeholder.\n",
        "BatchSize 是占了个位置，占好位置后，输入的数据在不断变化。\n",
        "Remark:\n",
        "1. placeholder is a type of tensor too.\n",
        "2. input datatype usually is `ndarray` from `numpy`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFyn7bIdsLbQ",
        "colab_type": "code",
        "outputId": "abbd8da4-80fd-446c-ff6c-0bfda5013beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "import numpy as np\n",
        "ph = tf.placeholder(dtype=tf.float32,shape=(None,3)) # None 那个位置其实就是一个 batchsize, which is changable.\n",
        "add_op = tf.add(ph,1)\n",
        "with tf.Session() as sess:\n",
        "  print(sess.run(add_op,feed_dict = {ph:np.random.rand(5,3)}))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.3998804 1.6061504 1.5851212]\n",
            " [1.7210946 1.5154355 1.2905102]\n",
            " [1.7051034 1.0635133 1.5128222]\n",
            " [1.6410382 1.0614496 1.8534691]\n",
            " [1.6128211 1.5241439 1.1005969]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqOM-6x9tbJs",
        "colab_type": "text"
      },
      "source": [
        "### 计算路径\n",
        "\n",
        "计算路径是指如果计算的 node 具有依赖关系，那么我们就会计算这些 node，沿着father node 寻找。Tensorflow 仅通过必需的节点自动进行计算 是这个框架的巨大优势。if there's a large graph with a lot unnecessary nodes,tensorflow would save a lot computation and time. 它允许我们构建大型的多用途graph, 这些graph 使用单个共享的核心node 集合，并根据所采取的不同的计算路径去做不同的事情。它只会关心它觉得重要/必要的路径。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e2D2iBQeyEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorflow会自动寻找依赖关系\n",
        "# 如果去掉feed_dict会报错\n",
        "tf.reset_default_graph()\n",
        "\n",
        "ph = tf.placeholder(tf.int32)\n",
        "\n",
        "three_node = tf.constant(3)\n",
        "\n",
        "sum_node = ph + three_node\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    #print(sess.run(three_node))\n",
        "    print(sess.run(sum_node,feed_dict={ph:15}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSaEYgFPlD86",
        "colab_type": "text"
      },
      "source": [
        "### `tf.assign`\n",
        "\n",
        "\n",
        "`tf.assign(target, value)`表示把`value`值赋值给`target`。`target`必须是一个可变的`tensor`(variable)可以没被初始化。`value`必须要有和`target`相同的数据类型和形状。\n",
        "\n",
        "思考一下如下的操作需要用到`tf.assign`吗？如果要用，对谁用？\n",
        "\n",
        "$\\theta = \\theta - \\beta \\nabla L(\\theta)$  ## 梯度向量法\n",
        "--> tf.assign($\\theta$ , $\\theta - \\beta \\nabla L(\\theta)$)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu9Fi4R3lnlT",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression\n",
        "\n",
        "线性回归可以看作是最简单的神经网络。我们使用4种方法来实现一个线性回归。\n",
        "\n",
        "- 解析法。\n",
        "- 人工求梯度。\n",
        "- 使用低阶API求梯度。\n",
        "- 使用高阶API求梯度。\n",
        "\n",
        "最常用3、4 方法。\n",
        "  |  \n",
        "  |  \n",
        "  v \n",
        "  \n",
        " easier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozpjHiycex_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "9302d8a3-a7d6-4926-bbaa-be3358a55f33"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
        "\n",
        "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "XT = tf.transpose(X)\n",
        "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
        "\n",
        "with tf.Session() as sess: \n",
        "    theta_value = theta.eval() ## have to assign the theta to a variable, since it would be released after the session.\n",
        "    print(theta_value)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-3.67372932e+01]\n",
            " [ 4.37366009e-01]\n",
            " [ 9.47520509e-03]\n",
            " [-1.08159676e-01]\n",
            " [ 6.48537397e-01]\n",
            " [-3.84734449e-06]\n",
            " [-3.79239232e-03]\n",
            " [-4.19136107e-01]\n",
            " [-4.32144403e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AviS4sv6ex8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "cb03c338-2804-4ad0-da63-972c1f3b5e75"
      },
      "source": [
        "import time\n",
        "tf.reset_default_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "data = housing.data\n",
        "scaled_housing_data_plus_bias = (data-np.mean(data,axis=0))/np.std(data,axis=0)\n",
        "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data_plus_bias]\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "\n",
        "\n",
        "\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\") # 相当于loss\n",
        "# 对 loss 进行梯度下降\n",
        "\n",
        "gradients = 2./m * tf.matmul(tf.transpose(X), error)\n",
        "\n",
        "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
        "\n",
        "init = tf.global_variables_initializer() \n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch%100==0: #批量梯度下降\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
        "            time.sleep(1)\n",
        "        sess.run(training_op)\n",
        "    best_theta = theta.eval() # save theta\n",
        "    print(best_theta)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 MSE = 4.855082\n",
            "Epoch 100 MSE = 0.6381838\n",
            "Epoch 200 MSE = 0.5704652\n",
            "Epoch 300 MSE = 0.55751604\n",
            "Epoch 400 MSE = 0.5488386\n",
            "Epoch 500 MSE = 0.5425051\n",
            "Epoch 600 MSE = 0.5378545\n",
            "Epoch 700 MSE = 0.5344304\n",
            "Epoch 800 MSE = 0.53190255\n",
            "Epoch 900 MSE = 0.530031\n",
            "[[ 2.0685523 ]\n",
            " [ 0.8420356 ]\n",
            " [ 0.14195044]\n",
            " [-0.24994995]\n",
            " [ 0.27564868]\n",
            " [ 0.00377547]\n",
            " [-0.04155352]\n",
            " [-0.7191171 ]\n",
            " [-0.6893291 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GEKCWmQex4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "e3277c6a-5d8f-4328-d9c4-56f08c8d9eef"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "data = housing.data\n",
        "scaled_housing_data_plus_bias = (data-np.mean(data,axis=0))/np.std(data,axis=0)\n",
        "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data_plus_bias]\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\") #loss\n",
        "\n",
        "gradients = tf.gradients(mse,theta) # loss 关于 theta 的梯度\n",
        "#前一个 gradients 是人求的，这一个是tf求的\n",
        "\n",
        "training_op = tf.assign(theta, theta - learning_rate * gradients[0])\n",
        "init = tf.global_variables_initializer() \n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch%100==0:\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
        "            time.sleep(1)\n",
        "        sess.run(training_op)\n",
        "    best_theta = theta.eval()\n",
        "    print(best_theta)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 MSE = 7.5094023\n",
            "Epoch 100 MSE = 0.72326267\n",
            "Epoch 200 MSE = 0.5605887\n",
            "Epoch 300 MSE = 0.5483131\n",
            "Epoch 400 MSE = 0.5428546\n",
            "Epoch 500 MSE = 0.53887355\n",
            "Epoch 600 MSE = 0.5358149\n",
            "Epoch 700 MSE = 0.5334431\n",
            "Epoch 800 MSE = 0.5315937\n",
            "Epoch 900 MSE = 0.53014416\n",
            "[[ 2.0685523 ]\n",
            " [ 0.7420637 ]\n",
            " [ 0.11559272]\n",
            " [-0.07530657]\n",
            " [ 0.13749456]\n",
            " [-0.0045165 ]\n",
            " [-0.03719198]\n",
            " [-1.0051216 ]\n",
            " [-0.96438694]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPiAHB5iex00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "4df54fb4-3394-43d5-873c-f961005708ad"
      },
      "source": [
        "## high-level API usage\n",
        "\n",
        "tf.reset_default_graph()\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "data = housing.data\n",
        "scaled_housing_data_plus_bias = (data-np.mean(data,axis=0))/np.std(data,axis=0)\n",
        "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data_plus_bias]\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
        "\n",
        "\n",
        "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9)# use momentum instead of gradient\n",
        "training_op = optimizer.minimize(mse) #optimize mse\n",
        "\n",
        "init = tf.global_variables_initializer() \n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch%100==0:\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
        "            time.sleep(1)\n",
        "        sess.run(training_op)\n",
        "    best_theta = theta.eval()\n",
        "    print(best_theta)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 MSE = 6.6729083\n",
            "Epoch 100 MSE = 0.53904\n",
            "Epoch 200 MSE = 0.52482295\n",
            "Epoch 300 MSE = 0.5243623\n",
            "Epoch 400 MSE = 0.524326\n",
            "Epoch 500 MSE = 0.5243217\n",
            "Epoch 600 MSE = 0.524321\n",
            "Epoch 700 MSE = 0.524321\n",
            "Epoch 800 MSE = 0.524321\n",
            "Epoch 900 MSE = 0.524321\n",
            "[[ 2.0685577 ]\n",
            " [ 0.82962555]\n",
            " [ 0.11875281]\n",
            " [-0.26553842]\n",
            " [ 0.30570585]\n",
            " [-0.00450268]\n",
            " [-0.0393265 ]\n",
            " [-0.8998717 ]\n",
            " [-0.8705278 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RseqrWasG3U",
        "colab_type": "text"
      },
      "source": [
        "## Save model \n",
        "A checkpoint for models.\n",
        "\n",
        "在模型的参数学习过程中，我们需要根据情况保存模型。根据前面的讲解知道神经网络的参数存储在`variable`中，`variable`的参数在`session`关闭后就会释放。所以我们需要在`session`打开的时候保存模型的参数。\n",
        "\n",
        "保存模型参数类似于`checkpoint`(切片快照)。在迭代的过程中，选择某一次快照一下然后保存到硬盘中。\n",
        "\n",
        "> 注意：模型保存在硬盘中有四个文件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPd2faWRexvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "theta = tf.Variable(tf.random_uniform([3, 1], -1.0, 1.0), name=\"theta\")\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "n_epochs = 1000\n",
        "with tf.Session() as sess: \n",
        "    sess.run(init)\n",
        "    for epoch in range(n_epochs):\n",
        "        # checkpoint every 100 epochs\n",
        "        if epoch % 100 == 0: \n",
        "            saver.save(sess, save_path=\"./model/my_model.ckpt\") #save models to local\n",
        "    print(theta.eval())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlzEgN7osmrU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "文件中主要保存了两类东西：\n",
        "\n",
        "1. 计算图(保存在meta文件中)\n",
        "2. variable的参数(保存在data文件中)\n",
        "\n",
        "---\n",
        "Two ways to load model we saved:\n",
        "\n",
        "1. 复制之前的代码，生成一摸一样的计算图，然后加载参数。\n",
        "2. 加载meta文件，将计算图加载回来，然后加载参数。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrP-tOlWexsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1st way\n",
        "tf.reset_default_graph()\n",
        "theta = tf.Variable(tf.random_uniform([3, 1], -1.0, 1.0), name=\"theta\")\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess: \n",
        "    saver.restore(sess,save_path=\"./model/my_model.ckpt\")\n",
        "    print(theta.eval())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US8dCNVuexo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2nd way: load the graph directly. \n",
        "# more convinient, but we don't know the paramters, like theta\n",
        "\n",
        "tf.reset_default_graph()\n",
        "saver = tf.train.import_meta_graph('./model/my_model.ckpt.meta')\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess,'./model/my_model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgtQ4dI6tPEi",
        "colab_type": "text"
      },
      "source": [
        "###  tf.get_collection vs tf.add_to_collection\n",
        "\n",
        "为了方便我们取出不同的operation，我们需要使用tf.add_to_collection和tf.get_collection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_CdHlatexlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "theta = tf.Variable(tf.random_uniform([3, 1], -1.0, 1.0), name=\"theta\")\n",
        "tf.add_to_collection('my_op',theta)\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "n_epochs = 1000\n",
        "with tf.Session() as sess: \n",
        "    sess.run(init)\n",
        "    for epoch in range(n_epochs):\n",
        "        # checkpoint every 100 epochs\n",
        "        if epoch % 100 == 0: \n",
        "            saver.save(sess, save_path=\"./model/my_model.ckpt\")\n",
        "    print(theta.eval())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXeJlq7cexhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "saver = tf.train.import_meta_graph('./model/my_model.ckpt.meta')\n",
        "my_op = tf.get_collection('my_op')\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess,'./model/my_model.ckpt')\n",
        "    print(sess.run(my_op[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKWMYIcLwfGS",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## TensorBoard\n",
        "\n",
        "TensorBoard is a visualization tool for tensorflow\n",
        "\n",
        "大致流程如下：\n",
        "\n",
        "1. 在你创建的图里面，选择你要汇总(summary)的节点。\n",
        "2. 因为你要对每一个汇总操作,进行sess.run，为了方便所以我们需要将所有操作进行汇总。(tf.summary.merge_all())。// 一次性操作\n",
        "3. 在sess中运行上面汇总的操作。\n",
        "4. use `tf.summary.FileWriter`,write the results into the file\n",
        "5. use tensorboard --logdir='path' to run the file\n",
        "\n",
        "\n",
        "### summary\n",
        "\n",
        "---\n",
        "```python\n",
        "#统计标量，比如loss,accuracy，得到时序图\n",
        "tf.summary.scalar(name,tensor)\n",
        "```\n",
        "---\n",
        "\n",
        "```python\n",
        "#统计张量，直方图统计，看weights,bias的分布\n",
        "tf.summary.histogram(name,tensor)\n",
        "```\n",
        "---\n",
        "\n",
        "```python\n",
        "# 将summary的操作进行汇总\n",
        "# inputs是个list\n",
        "# 一个表示部分汇总一个表示全部汇总\n",
        "merge_some=tf.summary.merge(inputs,collections=None,name=None)\n",
        "merge_summary=tf.summary.merge_all(key=tf.GraphKeys.SUMMARIES)\n",
        "```\n",
        "---\n",
        "\n",
        "Remark: \n",
        "1. All of the operation above happen in the defined graph.\n",
        "\n",
        "\n",
        "### 文件写入操作\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "#写入到硬盘的文件\n",
        "#这个操作把图写入文件中\n",
        "file_writer=tf.summary.FileWriter(logdir,graph,flush_secs)\n",
        "```\n",
        "---\n",
        "\n",
        "```python\n",
        "merge=sess.run(merge_some)\n",
        "file_writer.add_summary(merge,step)\n",
        "```\n",
        "\n",
        "注意，该操作是在sess会话中运行\n",
        "\n",
        "```python\n",
        "[...]\n",
        "for batch_index in range(n_batches):\n",
        "    X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size) \n",
        "    if batch_index % 10 == 0:\n",
        "        summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        step = epoch * n_batches + batch_index\n",
        "        file_writer.add_summary(summary_str, step)\n",
        "    sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "[...]\n",
        "```\n",
        "\n",
        "\n",
        " ---\n",
        "### run tensorboard\n",
        "\n",
        "```bash\n",
        "#path为目录地址\n",
        "tensorboard --logdir='path'\n",
        "```\n",
        "\n",
        "```bash\n",
        "#关于端口被占用的解决方法\n",
        "#default port is 6006\n",
        "lsof -i:6006\n",
        "kill -9 4969\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "#在浏览器中输入\n",
        " http://0.0.0.0:6006/ (or http://localhost:6006/)\n",
        "```\n",
        "\n",
        "6006倒过来就是goog的意思\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4usT1ecexeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorboard举例\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "data = housing.data\n",
        "scaled_housing_data_plus_bias = (data-np.mean(data,axis=0))/np.std(data,axis=0)\n",
        "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data_plus_bias]\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
        "\n",
        "# 定义写入的东西\n",
        "tf.summary.scalar('mse',mse)\n",
        "tf.summary.histogram('theta',theta)\n",
        "\n",
        "# 进行汇总\n",
        "merge_summary=tf.summary.merge_all(key=tf.GraphKeys.SUMMARIES)\n",
        "\n",
        "# 定义写入地址\n",
        "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "root_logdir = \"tf_logs\"\n",
        "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
        "# 打印写入的地址方便tensorboard使用\n",
        "print(logdir)\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer() \n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    # 定义写的文件（打开）\n",
        "    file_writer=tf.summary.FileWriter(logdir,sess.graph)\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch%100==0: # 每隔一段时间\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
        "        sess.run(training_op)\n",
        "         # 计算写入的值\n",
        "        summary_str = merge_summary.eval()\n",
        "        file_writer.add_summary(summary_str, epoch) #epoch相当于横坐标\n",
        "    best_theta = theta.eval()\n",
        "    print(best_theta)\n",
        "file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BD0ru1p_LJW",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### First NN project demo\n",
        "\n",
        "use mnist to do image clasiification.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLV121CTexab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import sys\n",
        "\n",
        "\n",
        "tf.reset_default_graph()\n",
        "epochs = 15\n",
        "batch_size = 100\n",
        "total_sum = 0\n",
        "epoch = 0\n",
        "\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "train_num = mnist.train.num_examples\n",
        "\n",
        "\n",
        "\n",
        "input_data = tf.placeholder(tf.float32,shape=(None,784))\n",
        "input_label = tf.placeholder(tf.float32,shape=(None,10))\n",
        "\n",
        "w1 = tf.get_variable(shape=(784,64),name='hidden_1_w')\n",
        "b1 = tf.get_variable(shape=(64),initializer=tf.zeros_initializer(),name='hidden_1_b')\n",
        "\n",
        "w2 = tf.get_variable(shape=(64,32),name='hidden_2_w')\n",
        "b2 = tf.get_variable(shape=(32),initializer=tf.zeros_initializer(),name='hidden_2_b')\n",
        "\n",
        "w3 = tf.get_variable(shape=(32,10),name='layer_output')\n",
        "\n",
        "#logit层\n",
        "output = tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(input_data,w1)+b1),w2)+b2),w3)\n",
        "\n",
        "loss = tf.losses.softmax_cross_entropy(input_label,output)\n",
        "\n",
        "#opt = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "opt = tf.train.AdamOptimizer()\n",
        "\n",
        "train_op = opt.minimize(loss)\n",
        "\n",
        "# 测试评估\n",
        "correct_pred = tf.equal(tf.argmax(input_label,axis=1),tf.argmax(output,axis=1))\n",
        "acc = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
        "\n",
        "tf.add_to_collection('my_op',input_data)\n",
        "tf.add_to_collection('my_op',output)\n",
        "tf.add_to_collection('my_op',loss)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "    sess.run([init])\n",
        "    test_data = mnist.test.images\n",
        "    test_label = mnist.test.labels\n",
        "    while epoch<epochs:\n",
        "        data,label=mnist.train.next_batch(batch_size)\n",
        "        data = data.reshape(-1,784)\n",
        "        total_sum+=batch_size\n",
        "        sess.run([train_op],feed_dict={input_data:data,input_label:label})\n",
        "        if total_sum//train_num>epoch:\n",
        "            epoch = total_sum//train_num\n",
        "            loss_val = sess.run([loss],feed_dict={input_data:data,input_label:label})\n",
        "            acc_test = sess.run([acc],feed_dict={input_data:test_data,input_label:test_label})\n",
        "            saver.save(sess, save_path=\"./model/my_model.ckpt\")\n",
        "            print('epoch:{},train_loss:{:.4f},test_acc:{:.4f}'.format(epoch,loss_val[0],acc_test[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ML1d59yexVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0stAHUHexRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h5Zk7LQexMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfZI4cq2exIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfuc4j-lexEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUv_HNUCexAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7s8L9UXew8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3djqquuew0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}